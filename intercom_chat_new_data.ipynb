{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590fabd1-ef62-4b59-88ff-448d0d33d127",
   "metadata": {},
   "source": [
    "# Conversations Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179360f0-0fac-4a65-b226-492dd21494bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import emoji\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from langdetect import detect\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340c075-1928-4885-a00c-c18a7f176a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a787b39-31e2-4100-ac61-d8f70c104f34",
   "metadata": {},
   "source": [
    "## Pull Raw Data - Download Customer Service conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv = pd.read_csv(f'{config[\"data\"][\"conversations_file\"]}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e55838e3e90386e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47e752ecc82c73ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7e3634d523f47b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "### Transform create_at column to datetime"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd6df98a4b2ba82c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv['created_at'] = pd.to_datetime(df_conv['created_at'], errors='coerce')\n",
    "df_conv.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a353550e6109ecd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if all tweet ids are unique - they should be\n",
    "print(\"Row_count:\", df_conv.shape[0])\n",
    "print(\"N tweet id:\", df_conv['tweet_id'].nunique())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ace0c06626f233f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order data by create date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3be646c782f88a3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeb43919dba8f616"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv.sort_values(by='created_at', ignore_index=True, inplace=True)\n",
    "df_conv.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ddda998e4d8c49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add conversation_id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2b6877896e636c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make a new column called conversation_id \n",
    "df_conv['conversation_id'] = df_conv['tweet_id']\n",
    "whole = df_conv.shape[0]\n",
    "for i in range(len(df_conv)):\n",
    "    if i % 50000 == 0:\n",
    "        print(\"{} out of {} were preprocessed\".format(i, whole))\n",
    "    prev_tweet = df_conv.loc[i, 'in_response_to_tweet_id']\n",
    "    if not np.isnan(prev_tweet):\n",
    "        df_temp = df_conv[df_conv['tweet_id']==prev_tweet]\n",
    "        if len(df_temp) > 0:\n",
    "            new_conv_id = df_temp['conversation_id'].values[0]\n",
    "            df_conv.loc[i, 'conversation_id'] = new_conv_id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abbb89a34e8ecd9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the above statement was started at: 13:12\n",
    "# the above statement finished at: 15:44 it was finished"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bc528ca8427c9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6083eaad5616736"
  },
  {
   "cell_type": "markdown",
   "source": [
    "One conversation can include more than 2 authors, it can be multiple users struggling with same issue and one person from support, see example below"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "259e4af4d00f6300"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv[df_conv['conversation_id']==119250]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d8a5750c93275a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add author_type"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a26ebb1a60379f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(df_conv['author_id'].value_counts().to_frame().reset_index()).sort_values('count', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0bb35ee3d97ff92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv['author_type'] = df_conv['author_id'] .map(lambda x: \"user\" if x.isnumeric() else \"support\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4100b089cae7be5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv[[\"author_id\", \"author_type\"]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52e104aaf29e0238"
  },
  {
   "cell_type": "markdown",
   "id": "0ede5eb0-ab41-434b-b79f-9502da7ab8ff",
   "metadata": {},
   "source": [
    "### Filter out links to previous tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv_filtered = df_conv.copy(deep=True)\n",
    "df_conv_filtered['text'] = df_conv_filtered['text'].apply(lambda s: re.sub(\"@\\S+ |@\\S+$\", \"\", s))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66070244c057b6d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# before filtering out links to previous tweets\n",
    "selected_conv_id = 1278330\n",
    "for idx, item in df_conv.loc[df_conv['conversation_id'] == selected_conv_id, :].iterrows():\n",
    "    print(f\"{idx} | {item['author_id']} | {item['text']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffedf915422dd66f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# after filtering out links to previous tweets\n",
    "selected_conv_id = 1278330\n",
    "for idx, item in df_conv_filtered.loc[df_conv_filtered['conversation_id'] == selected_conv_id, :].iterrows():\n",
    "    print(f\"{idx} | {item['author_id']} | {item['text']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae81de07cf9a97af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# before filtering out links to previous tweets\n",
    "selected_conv_id = 2763707\n",
    "for idx, item in df_conv.loc[df_conv['conversation_id'] == selected_conv_id, :].iterrows():\n",
    "    print(f\"{idx} | {item['author_id']} | {item['text']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fba8db0dc11ff67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# after filtering out links to previous tweets\n",
    "selected_conv_id = 2763707\n",
    "for idx, item in df_conv_filtered.loc[df_conv_filtered['conversation_id'] == selected_conv_id, :].iterrows():\n",
    "    print(f\"{idx} | {item['author_id']} | {item['text']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c40515de68ab161e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add parameters linked to body length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "339fde96caa42f47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add number of characters in the utterance \n",
    "df_conv_filtered['utterance_size'] = df_conv_filtered['text'].str.len()\n",
    "\n",
    "# Add number of tokens in the utterance \n",
    "df_conv_filtered['utterance_tokens_size'] = df_conv_filtered['text'].apply(lambda x: len(str(x).split(' ')))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2f524acb0619c10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# after filtering out links to previous tweets\n",
    "selected_conv_id = 2763707\n",
    "df_conv_filtered.loc[df_conv_filtered['conversation_id'] == selected_conv_id, :]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19da2c44f8fc4df2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c96b57f85295dfb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of unique conversations before filtering\n",
    "print(\"Number of unique conversations before filtering:\", df_conv['conversation_id'].nunique())\n",
    "# Number of tweets before filtering\n",
    "print(\"Number of tweets before filtering:\", df_conv['tweet_id'].nunique())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80ea3cf0-0d71-4596-8cfd-cd5714b25c6f"
  },
  {
   "cell_type": "markdown",
   "id": "ad76e5ab-c9c7-4cb4-a6f4-c957442d4431",
   "metadata": {},
   "source": [
    "#### Filter out empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64876a02-3fb7-4736-8c16-50dfec848506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter\n",
    "df_conv_filtered = df_conv_filtered[df_conv_filtered['text']!=\"\"]\n",
    "# Number of unique conversations after filtering\n",
    "print(\"Number of unique conversations after filtering:\", df_conv_filtered['conversation_id'].nunique())\n",
    "# Number of tweets after filtering\n",
    "print(\"Number of tweets after filtering:\", df_conv_filtered['tweet_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b9a1d-10a6-4512-a573-c3d910a9b822",
   "metadata": {},
   "source": [
    "#### Filter out emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ababd991-9829-4c34-9c26-7ccfe1fa38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_filtered_emot = df_conv_filtered['text'].apply(lambda s: emoji.replace_emoji(s, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f6b8d-bf9a-4a87-9d58-45b2b7430552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example before filtering\n",
    "print(df_conv.loc[1768087, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208e293-7b65-4f27-a046-240328c12d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example after filtering\n",
    "print(df_conv_filtered_emot[1768087])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9bdff-891d-456c-918e-11923483ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter\n",
    "df_conv_filtered['text'] = df_conv_filtered_emot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79eff3-04cd-4108-8f19-85db67a1ec2a",
   "metadata": {},
   "source": [
    "#### Filter out empty and one char strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d223c0-fe80-4ca8-8290-088806abc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter\n",
    "df_conv_filtered = df_conv_filtered.loc[df_conv_filtered['utterance_size'] > 1, :]\n",
    "# Number of unique conversations after filtering\n",
    "print(\"Number of unique conversations after filtering empty strings:\", df_conv_filtered['conversation_id'].nunique())\n",
    "# Number of tweets after filtering\n",
    "print(\"Number of tweets after filtering empty strings:\", df_conv_filtered['tweet_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba000a3-2966-46c3-b63d-ebf308046962",
   "metadata": {},
   "source": [
    "#### Replace web links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8503a2-0c84-474e-9cde-9e06ce209db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace web links in utterances/messages by '[link]' label\n",
    "LINK_CLEANER = re.compile(r'\\b(?:https?://)\\S+', flags=re.IGNORECASE)\n",
    "df_conv_filtered['text'] = df_conv_filtered['text'].str.replace(LINK_CLEANER, '[link]', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711e76d-3868-49ad-a240-b27ffd51efd7",
   "metadata": {},
   "source": [
    "#### Remove additinal whitespaces and align punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3585ff-e314-4034-bcdb-d2cdfba64430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove additinal whitespaces\n",
    "WHITESPACES_CLEANER = re.compile(r'(\\uFEFF|\\s)+')\n",
    "df_conv_filtered['text'] = df_conv_filtered['text'].str.replace(WHITESPACES_CLEANER, ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f6922-c5a3-4b25-9fc9-0e33cb80f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align punctuation\n",
    "WHITESPACES_BEFORE_PUNCTUATION_CLEANER = re.compile(r'(\\w)\\s+([.,;:?!])')\n",
    "df_conv_filtered['text'] = df_conv_filtered['text'].str.replace(WHITESPACES_BEFORE_PUNCTUATION_CLEANER, r'\\1\\2', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4141a-082b-4892-a3dd-1d854949e4d7",
   "metadata": {},
   "source": [
    "### Add language info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc41b22-b34d-4533-a607-2b479ccb93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(x):\n",
    "    try:\n",
    "        lang = detect(x)\n",
    "    except:\n",
    "        lang = 'unknown'\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4ca89-973c-4ca6-a06f-d114a4e47088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_filtered_lang = df_conv_filtered.loc[:, 'text'].apply(lambda x: detect_lang(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8a1176374d6a7964"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cca678-c62d-4b74-a90e-37e4873d829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_filtered['utterance_lang'] = df_conv_filtered_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146e0f2-c3b3-4865-be54-3d35256afd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lang = df_conv_filtered.groupby(['conversation_id']).apply(lambda x: x.sort_values('utterance_size', ascending=False).iloc[0]['utterance_lang'])\n",
    "df_conv_lang = conv_lang.to_frame().rename(columns={0: \"conversation_lang\"})\n",
    "df_conv_lang_counts = df_conv_lang.value_counts().reset_index().rename(columns={0: 'count'})\n",
    "df_conv_lang_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c168a8-0c26-4ad3-958a-6a37029d3780",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_conv_lang_counts, x='conversation_lang', y='count',\n",
    "             title=\"Number of conversations in a given language\",\n",
    "            height=600,\n",
    "            # text_auto=True\n",
    "            )\n",
    "fig.update_layout(xaxis_title='Conversation language',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f139e3-c690-4e6c-adb6-991d5670b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge detected language info with other data \n",
    "df_conv_filtered = df_conv_filtered.merge(df_conv_lang, left_on='conversation_id', right_index=True)\n",
    "df_conv_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7fd4e0-98a1-492f-9aa8-32588797c7df",
   "metadata": {},
   "source": [
    "## Read/write preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387098b-e11a-49c5-8972-6fd33f5ae184",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data to file\n",
    "# df_conv_filtered.to_csv(f'{config[\"data\"][\"data_folder\"]}/twitter_sample.csv')\n",
    "# df_conv_filtered.to_parquet(f'{config[\"data\"][\"data_folder\"]}/twitter_sample.parq')\n",
    "# df_conv_filtered.to_csv(f'{config[\"data\"][\"data_folder\"]}/twitter_entire_dataset.csv')\n",
    "# df_conv_filtered.to_parquet(f'{config[\"data\"][\"data_folder\"]}/twitter_entire_dataset.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d42e0b-79d5-4be2-b927-b399a6abdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "print(os.getcwd())\n",
    "df_conv_filtered = pd.read_parquet(f'{config[\"data\"][\"data_folder\"]}/twitter_entire_dataset.parq')\n",
    "\n",
    "df_conv_filtered['created_at'] = pd.to_datetime(df_conv_filtered['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1af82-2ea9-4185-a3c8-3cf228bc26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA\n",
    "### Number of conversations over time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a63d9f8edd64b6ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv_created = df_conv_filtered[['conversation_id', 'created_at']]\n",
    "df_conv_created['created_month']= df_conv_filtered['created_at'].dt.strftime('%Y-%m')\n",
    "# df_conv_created"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df8405fc9b54a52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv_vs_time = df_conv_created.groupby('created_month', as_index=False).agg(\n",
    "                conversation_count=pd.NamedAgg(column=\"conversation_id\", aggfunc=\"nunique\"),\n",
    ")\n",
    "# df_conv_vs_time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e36724d941301b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.bar(df_conv_vs_time[(df_conv_vs_time['created_month']>='2014-01') & (df_conv_vs_time['created_month']<='2024-04')], x='created_month', y='conversation_count',\n",
    "             title=\"Number of conversations over time\",\n",
    "            height=600,\n",
    "            text_auto='.2s'\n",
    "            )\n",
    "fig.update_layout(xaxis_title='Created month',\n",
    "                  yaxis_title='Count')\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "361ddb9b61d71ec6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check number of characters per conversation and number of tweets per conversation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9322078dc3656fc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv_length = df_conv_filtered.groupby('conversation_id').agg(\n",
    "                conversation_length=pd.NamedAgg(column=\"tweet_id\", aggfunc=\"count\"),\n",
    "                conversation_size=pd.NamedAgg(column=\"utterance_size\", aggfunc=\"sum\")\n",
    ")\n",
    "df_conv_length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bce5a8c42e2533c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv_length.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e2e9882-6f08-4bcd-92c5-3cf3ed3217cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_count_vs_length = (df_conv_length['conversation_length'].value_counts().to_frame().reset_index()).sort_values('count')\n",
    "conversation_count_vs_length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d238f4c8253e0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Distribution of number of tweets within conversations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cbf09e0ec0bfe03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.bar(conversation_count_vs_length, x='conversation_length', y='count',\n",
    "             title=\"Number of conversations vs. conversation length\",\n",
    "            height=600,\n",
    "            # text_auto=True\n",
    "            )\n",
    "fig.update_xaxes(range=[0, 50])\n",
    "fig.update_layout(xaxis_title='Conversation length',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56ffb5d1ff5d674b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Distribution of number of characters (length) of conversations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8035c8246bd462c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.histogram(df_conv_length, x='conversation_size', \n",
    "             title=\"Distribution of conversation size\",\n",
    "            # nbins=100,\n",
    "            height=600,\n",
    "            # text_auto=True\n",
    "            )\n",
    "fig.update_xaxes(range=[0, 1000])\n",
    "fig.update_layout(xaxis_title='Conversation size',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b74fdfbed957da85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For each conversation length (number of tweets in conversation) how many come from the users and how many from the support"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "446118ec3fea27d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "author_conversation = df_conv_filtered.groupby(['conversation_id', 'author_type'], as_index=True).agg(\n",
    "                author_conversation_count=pd.NamedAgg(column=\"tweet_id\", aggfunc=\"count\")\n",
    ").merge(df_conv_length, left_index=True, right_index=True).reset_index(level=1)\n",
    "author_conversation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a869c17dcdbe184f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "author_conversation_count = author_conversation.groupby(['conversation_length', 'author_type'], as_index=False).sum()\n",
    "author_conversation_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c75a0b3457b2712"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "author_conversation_count = author_conversation_count.merge(conversation_count_vs_length, on='conversation_length')\n",
    "author_conversation_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9127201345f3b3e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "author_conversation_count['author_conversation_rate'] = author_conversation_count['author_conversation_count'] / (author_conversation_count['conversation_length'] * author_conversation_count['count'])\n",
    "author_conversation_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bad5430654392736"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.bar(author_conversation_count, x=\"conversation_length\", y=\"author_conversation_rate\", color=\"author_type\", \n",
    "             hover_data=['author_conversation_count', 'count'],\n",
    "             title=\"Author conversation rate vs. conversation length\",\n",
    "            height=600,\n",
    "            )\n",
    "fig.update_xaxes(range=[0, 20])\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f80ac50ff17ea86e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking the distribution of number of tokens (words) in each tweet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d88f905545f4e98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.histogram(df_conv_filtered, x='utterance_tokens_size', \n",
    "             title=\"Distribution of number of tokens in message/utterance\",\n",
    "            height=600,\n",
    "            )\n",
    "fig.update_xaxes(range=[0, 100])\n",
    "fig.update_layout(xaxis_title='Number of tokens',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd9b4e7e3fea3fb6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv_filtered[['utterance_tokens_size']].describe(percentiles=np.arange(0.1, 1, 0.1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17afa0ed68abdfa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_conv_filtered[['utterance_tokens_size']].quantile(0.95)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d1cf1707418ae6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking number of conversation in each language"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8985af2e03981646"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_lang = df_conv_filtered.groupby(['conversation_id']).apply(lambda x: x.sort_values('utterance_size', ascending=False).iloc[0]['utterance_lang'])\n",
    "df_conv_lang = conv_lang.to_frame().rename(columns={0: \"conversation_lang\"})\n",
    "df_conv_lang_counts = df_conv_lang.value_counts().reset_index().rename(columns={0: 'count'})\n",
    "df_conv_lang_counts.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cd7ec8781d8116a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.bar(df_conv_lang_counts, x='conversation_lang', y='count',\n",
    "             title=\"Number of conversations in a given language\",\n",
    "            height=600,\n",
    "            # text_auto=True\n",
    "            )\n",
    "fig.update_layout(xaxis_title='Conversation language',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79b56e0263e5cc14"
  },
  {
   "cell_type": "markdown",
   "id": "041a7b75-ee2a-49ad-ab5f-0d3ffc177635",
   "metadata": {},
   "source": [
    "## Sample chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4863220-1f37-481b-957e-1e4ca6f49870",
   "metadata": {},
   "source": [
    "### Manually selected chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffb86b-4497-44de-9012-97c5ffdf3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_conv_id = 119246"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912025f-1bd5-43fe-bc90-78552d3847cd",
   "metadata": {},
   "source": [
    "Selected conversation before perprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1affa10-1bdb-4c34-bb5e-86a406eae371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, item in df_conv.loc[df_conv['conversation_id']==selected_conv_id, :].iterrows():\n",
    "#     print(f\"{idx} | {item['author_type']} | {item['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea1fee7-45d7-42a9-9d67-c80a28bc2853",
   "metadata": {},
   "source": [
    "The same conversation after preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c318b-2d57-4e33-91d1-7988ff05be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in df_conv_filtered.loc[df_conv_filtered['conversation_id']==selected_conv_id, :].iterrows():\n",
    "    print(f\"| {item['author_type']} | {item['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda9749-a4ad-4917-b8d9-0f95508852ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_filtered.loc[df_conv_filtered['conversation_id']==selected_conv_id, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470a639-a574-4830-92ef-c81d9d1e689e",
   "metadata": {},
   "source": [
    "### Randomly selected chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72e535-8809-4b1c-9908-9ce7b97790f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=11)\n",
    "\n",
    "sample_conv_ids = rng.choice(df_conv_filtered['conversation_id'].unique(), 10, replace=False)\n",
    "# sample_conv_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce7afc-f3bf-48f2-8af0-c9c754e19256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conv_id in sample_conv_ids:\n",
    "    print('-'*10 + str(conv_id) + '-'*10)\n",
    "    for idx, item in df_conv_filtered.loc[df_conv_filtered['conversation_id']==conv_id, :].iterrows():\n",
    "        print(f\"{item['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50bb33-ed77-4d2a-a8c7-6e2d43aabf53",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1a339-1123-4e33-9450-ce30a9e7f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech, TextGeneration\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60895ca6-ea05-47ce-a98d-01427a2f3659",
   "metadata": {},
   "source": [
    "## Prepare conversation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97812fbc-ec8a-408f-8472-0e6a58b2ea88",
   "metadata": {},
   "source": [
    "### Select time frames and English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdd51e-715e-476c-a40e-5aad8cd5542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique conversations before selection\n",
    "df_conv_filtered['conversation_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd25e6f-0d0a-4a79-ad1e-4c233d7529bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_filtered['created_date'].min(), df_conv_filtered['created_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9869c7b-aa28-43a4-a800-f1b2e38e111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date = '2022-01-01'\n",
    "end_date = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae525a-74fe-4720-ba79-39705842eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_mask = (df_conv_filtered['created_date'] >= begin_date) & \\\n",
    "                 (df_conv_filtered['created_date'] < end_date) & \\\n",
    "                 (df_conv_filtered['conversation_lang'] == 'en')\n",
    "df_conv_selected = df_conv_filtered[selection_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e850f-4bc7-43de-a31e-a17ab302b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_selected['created_date'].min(), df_conv_selected['created_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876f05d-b272-41f9-8dc0-c41bc47686a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique conversations after selection\n",
    "df_conv_selected['conversation_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of unique organizations\n",
    "df_conv_selected['author_domain'].nunique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdd0beba2bf42abf"
  },
  {
   "cell_type": "markdown",
   "id": "e4e87278-064c-467e-9021-b9f8b0975bb8",
   "metadata": {},
   "source": [
    "### Cut too long messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef97228-9285-46af-9ae0-c091b76869e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max_tokens is set based on distribution of number of tokens in message/utterance\n",
    "max_tokens = 120\n",
    "\n",
    "df_conv_selected['body'] = df_conv_selected['body'].apply(lambda x: ' '.join(str(x).split(' ')[:max_tokens]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b41647-96e2-4754-9f96-db122ed415a9",
   "metadata": {},
   "source": [
    "### Join messages into one conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f23ef1-f04b-4b55-b164-59e920ac0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations = df_conv_selected.groupby(['conversation_id'], as_index=False).agg(\n",
    "                conversation_length=pd.NamedAgg(column=\"id\", aggfunc=\"count\"),\n",
    "                conversation_body=pd.NamedAgg(column=\"body\", aggfunc=lambda x: '\\n'.join(x.astype(str))), \n",
    "                conversation_date=pd.NamedAgg(column=\"created_date\", aggfunc=\"first\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a2350d-321e-41a5-9602-2b21f1988002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of tokens (words) in each conversation\n",
    "df_conversations_tokens = df_conv_selected[['conversation_id', 'body']].groupby(['conversation_id'])['body']\\\n",
    "    .apply(lambda x: len(nltk.word_tokenize(' '.join(x.astype(str))))).to_frame().reset_index().rename(columns={'body': 'tokens_count'})\n",
    "\n",
    "df_conversations_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9d04a-ba91-4e6e-bdaa-c3068fbe370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add info about number of tokens\n",
    "df_conversations = df_conversations.merge(df_conversations_tokens, how='left', on='conversation_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa91fa-dd2d-4231-ac86-d7369780d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_conversations, x='tokens_count', \n",
    "             title=\"Distribution of number of tokens in conversations\",\n",
    "            # nbins=100,\n",
    "            height=600,\n",
    "            # text_auto=True\n",
    "            )\n",
    "fig.update_xaxes(range=[0, 1500])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde802bb-8f7f-4846-8683-61126c3d9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations.describe(percentiles=np.arange(0.1, 1, 0.1))[['tokens_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efed87-519f-4bc3-8de4-4a43db52ea76",
   "metadata": {},
   "source": [
    "### Remove duplicated conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ea77c-ab86-4a31-af85-c81181a88db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All duplicated conversations ('keep=False' marks all duplicates as True)\n",
    "\n",
    "df_duplicated_convs = df_conversations.loc[df_conversations['conversation_body'].duplicated(keep=False), :]\n",
    "df_duplicated_convs['conversation_month']= df_duplicated_convs['conversation_date'].dt.strftime('%Y-%m')\n",
    "\n",
    "df_duplicated_convs#.to_csv('duplicated_conv.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbd8d1-c6c7-460e-837e-e04f776693ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicated_convs_per_month = df_duplicated_convs.groupby('conversation_month', as_index=False)[['conversation_id']].count()\n",
    "\n",
    "fig = px.bar(df_duplicated_convs_per_month[df_duplicated_convs_per_month['conversation_month']>='2023-01'], x='conversation_month', y='conversation_id',\n",
    "             title=\"Number of duplicated conversations per month\",\n",
    "            height=600,\n",
    "            text_auto=\".2s\"\n",
    "            )\n",
    "fig.update_layout(xaxis_title='Month',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7e830-41ca-4b53-81ac-7302a824d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates by month\n",
    "df_duplicated_convs_month_count = df_duplicated_convs.groupby(['conversation_body', 'conversation_month'], as_index=False).agg(\n",
    "    conversations_count=pd.NamedAgg(column=\"conversation_id\", aggfunc=\"count\"),\n",
    ")\n",
    "\n",
    "df_duplicated_convs_month_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d442f1-c0e9-464e-a05a-c2aa528d13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates and represent duplicates by the first occurrence\n",
    "df_duplicated_convs_count = df_duplicated_convs.groupby('conversation_body', as_index=False).agg(\n",
    "    conversations_count=pd.NamedAgg(column=\"conversation_id\", aggfunc=\"count\"),\n",
    "    conversation_id=pd.NamedAgg(column=\"conversation_id\", aggfunc=\"first\")\n",
    ")[['conversation_id', 'conversation_body', 'conversations_count']].sort_values('conversations_count', ascending=False)\n",
    "\n",
    "df_duplicated_convs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577b7d2-6a68-48b3-a827-8d14a987b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_conversations[df_conversations['conversation_body'].duplicated()], x='conversation_length', \n",
    "             title=\"Distribution of conversation_length in duplicated conversations\",\n",
    "            # nbins=100,\n",
    "            height=600,\n",
    "            # text_auto=True\n",
    "            )\n",
    "# fig.update_xaxes(range=[0, 1000])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f72226-2bda-406b-897d-0762fb0f22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unique conversations\n",
    "df_conversations_unique = df_conversations[~df_conversations['conversation_body'].duplicated()].reset_index(drop=True)\n",
    "df_conversations_unique['conversation_month']= df_conversations_unique['conversation_date'].dt.strftime('%Y-%m')\n",
    "df_conversations_unique = df_conversations_unique.merge(df_duplicated_convs_count, how='left', on=['conversation_id', 'conversation_body'])\n",
    "df_conversations_unique = df_conversations_unique.fillna({'conversations_count': 1}).astype({'conversations_count': int})\n",
    "df_conversations_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972d123-599d-49ef-856c-b261fa697a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency check\n",
    "df_conversations_unique.shape[0], df_conversations_unique['conversations_count'].sum(), df_conversations.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429d1b8-d2b9-4390-866d-e799f50d1d4c",
   "metadata": {},
   "source": [
    "### Define final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017dbe33-59df-470f-a9a0-f6dff298a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique conversations 2022-2023\n",
    "conversations_data = df_conversations_unique['conversation_body'].tolist()\n",
    "len(conversations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6335bf-1d20-4dfa-b128-7e63d6c42ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = df_conversations_unique['conversation_date'].dt.strftime('%Y-%m').to_list()\n",
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00831043-733d-42fa-8898-cfd5d195566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations_unique['conversation_date'].min(), df_conversations_unique['conversation_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2089935-6fbe-4fa9-8383-cfdf33b0aded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfdcaec-bbfc-4a6a-8a97-9e87d49c119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All conversations in 2023\n",
    "df_conversations[(df_conversations['conversation_date'] >= '2023-01-01') & \\\n",
    "                 (df_conversations['conversation_date'] < '2024-01-01')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d83298-003a-4483-9628-77bdd28f2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mask for unique conversations in 2023\n",
    "conv_2023_mask = (df_conversations_unique['conversation_date'] >= '2023-01-01') & \\\n",
    "                 (df_conversations_unique['conversation_date'] < '2024-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b560997-c991-4275-a411-ffb4cfa8f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique conversations in 2023\n",
    "conversations_data_2023 = df_conversations_unique.loc[conv_2023_mask, 'conversation_body'].tolist()\n",
    "len(conversations_data_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b3b04-5944-4aa6-9ee5-aaf55f9c36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_2023 = df_conversations_unique.loc[conv_2023_mask, 'conversation_date'].dt.strftime('%Y-%m').to_list()\n",
    "len(timestamps_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe9e0a-c213-490a-ac20-b7292a15be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations_unique.loc[conv_2023_mask, 'conversation_date'].min(), df_conversations_unique.loc[conv_2023_mask, 'conversation_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d9c7c-c551-4006-8efb-76e8ce7e0746",
   "metadata": {},
   "source": [
    "## Define stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41da31-a554-456a-8d0c-6136f8fc04b7",
   "metadata": {},
   "source": [
    "Stopwords list downloaded from https://github.com/stopwords-iso/stopwords-en/blob/master/stopwords-en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb897e-507d-4355-92e4-faf83902b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = pd.read_csv('stopwords-en.txt', header=None).astype(str)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ac361-b75e-45a3-98b9-957c952cd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb7a04-f95e-446b-b3f1-08fcad8b8167",
   "metadata": {},
   "source": [
    "## Detailed BERTopic pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b5020-796f-4006-a0f6-54208b2ee6ac",
   "metadata": {},
   "source": [
    "### Step 1 - Embedding documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf0933-5e9a-4219-8ac0-1fdf2aac8f04",
   "metadata": {},
   "source": [
    "##### Pre-calculate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f9b9b-0555-4ff8-8f5c-e87d9b052412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\") # It takes ~20m to make an embeddng for ~30k chats\n",
    "# conversations_embeddings = embedding_model.encode(conversations_data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5b0ef-94c9-4b37-838f-7fb01477a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversations_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e2460-04ad-4407-ac3f-5cd953b4b54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ea431-0053-4afc-9028-b02229681978",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_gte_base = SentenceTransformer('thenlper/gte-base')\n",
    "conversations_embeddings_gte_base_2022_2023 = embedding_model_gte_base.encode(conversations_data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8a295-3f46-4ebd-8abf-b63cbeb95541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store sentences & embeddings on disc\n",
    "with open(\"embeddings_gte_base_2022-2023.pkl\", \"wb\") as fOut:\n",
    "    pickle.dump({\"conversations\": conversations_data, \"embeddings\": conversations_embeddings_gte_base_2022_2023}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load sentences & embeddings from disc\n",
    "# with open(\"embeddings_gte_base_2022-2023.pkl\", \"rb\") as fIn:\n",
    "#     stored_data = pickle.load(fIn)\n",
    "#     conversations_data = stored_data[\"conversations\"]\n",
    "#     conversations_embeddings_gte_base_2022_2023 = stored_data[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7556bc-af59-4b68-b932-bc882c2e8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_embeddings_gte_base_2022_2023.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3178b15-625a-4704-a1bc-992cd245fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conversations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9410d-4367-4722-a8b1-f0f8115bd335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings for conversations 2023\n",
    "conversations_embeddings_gte_base_2023 = conversations_embeddings_gte_base_2022_2023[conv_2023_mask]\n",
    "conversations_embeddings_gte_base_2023.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de23d3-570a-48ac-bfbf-ce2f3ffefa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conversations_data_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28dd56f-12cb-409d-986d-50f458ae4cc2",
   "metadata": {},
   "source": [
    "### Step 2 - Reducing dimensionality of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d63c5-dcfe-4b3a-b74c-c0de95be25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent stochastic behavior set random_state\n",
    "# umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7ce37-5b55-4d8c-860f-4a89a79fbde7",
   "metadata": {},
   "source": [
    "### Step 3 - Clustering reduced embeddings into topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13016006-d36e-4a4c-8506-ed6fda54c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141b158-e7e3-45f7-9d50-6c0c43ebb0b5",
   "metadata": {},
   "source": [
    "### Step 4 - Tokenization of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc738402-747e-4dc9-aa3f-3588d4702ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer_model = CountVectorizer(stop_words=stopwords_list, min_df=10, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e52c1-94c4-457c-bb05-8a54cccc7e47",
   "metadata": {},
   "source": [
    "### Step 5 - Weight tokens, create topic representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8a074-329b-4fad-8126-28a5dab34bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a49607d-d0b9-472e-bdce-1bc809212159",
   "metadata": {},
   "source": [
    "### Step 6 - (Optional) Fine-tune topic representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a75f5-1186-48a8-87ad-ba4ecd18dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KeyBERT\n",
    "# keybert_model = KeyBERTInspired()\n",
    "\n",
    "# # Part-of-Speech\n",
    "# pos_model = PartOfSpeech(\"en_core_web_sm\")\n",
    "\n",
    "## MMR\n",
    "# mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "## GPT-3.5\n",
    "# client = openai.OpenAI(api_key=\"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\")\n",
    "# prompt = \"\"\"\n",
    "# I have a topic that contains the following documents: \n",
    "# [DOCUMENTS]\n",
    "# The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "# Based on the information above, extract a short but highly descriptive topic label of at most 5 words. Make sure it is in the following format:\n",
    "# topic: <topic label>\n",
    "# \"\"\"\n",
    "# openai_model = OpenAI(client, model=\"gpt-3.5-turbo\", exponential_backoff=True, chat=True, prompt=prompt)\n",
    "\n",
    "\n",
    "# # All representation models\n",
    "# representation_model = {\n",
    "#     \"KeyBERT\": keybert_model,\n",
    "#     # \"OpenAI\": openai_model,\n",
    "#     \"MMR\": mmr_model,\n",
    "#     \"POS\": pos_model\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c2b4f2-2eda-49f6-83b8-417465497936",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdfa09-6043-45ab-8f86-135f74e3082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=stopwords_list, min_df=10, ngram_range=(1, 2))\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "keybert_model = KeyBERTInspired()\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model,\n",
    "}\n",
    "\n",
    "conv_topic_model_1 = BERTopic(\n",
    "  # Pipeline models\n",
    "  embedding_model=embedding_model_gte_base,           # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                     # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,               # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,         # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                 # Step 5 - Extract topic words\n",
    "  representation_model=representation_model, # Step 6 - (Optional) Fine-tune topic represenations\n",
    "    \n",
    "  # Hyperparameters\n",
    "  top_n_words=10, # 10 is default\n",
    "  # nr_topics=\"auto\",\n",
    "  calculate_probabilities=True,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119c28a-a978-42b6-aef2-136d3cb2b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=80, min_samples=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=stopwords_list, min_df=10, ngram_range=(1, 2))\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "keybert_model = KeyBERTInspired()\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model,\n",
    "}\n",
    "\n",
    "conv_topic_model_2 = BERTopic(\n",
    "  # Pipeline models\n",
    "  embedding_model = embedding_model_gte_base,     # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                     # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,               # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,         # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                 # Step 5 - Extract topic words\n",
    "  representation_model=representation_model, # Step 6 - (Optional) Fine-tune topic represenations\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10, # 10 is default\n",
    "  # nr_topics=\"auto\",\n",
    "  calculate_probabilities=True,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6613a8d-3f73-4adc-8631-0e62a103d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=80, min_samples=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=stopwords_list, min_df=10, ngram_range=(1, 2))\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "keybert_model = KeyBERTInspired()\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model,\n",
    "}\n",
    "\n",
    "conv_topic_model_3 = BERTopic(\n",
    "  # Pipeline models\n",
    "  embedding_model=embedding_model_gte_base,       # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                     # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,               # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,         # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                 # Step 5 - Extract topic words\n",
    "  representation_model=representation_model, # Step 6 - (Optional) Fine-tune topic represenations\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10, # 10 is default\n",
    "  # nr_topics=\"auto\",\n",
    "  calculate_probabilities=True,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76370fa-c479-494c-8608-6c92193a28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warning:\n",
    "# The current process just got forked. Disabling parallelism to avoid deadlocks... To disable this warning, please explicitly set \n",
    "# TOKENIZERS_PARALLELISM=(true | false)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306d979-4dfd-4fdb-b867-c7b12f7745ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topics_1, conv_probs_1 = conv_topic_model_1.fit_transform(conversations_data_2023, conversations_embeddings_gte_base_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efd601-a6da-4f2c-ab57-36dbf88dbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topics_2, conv_probs_2 = conv_topic_model_2.fit_transform(conversations_data_2023, conversations_embeddings_gte_base_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8daab-020b-4d3a-95d9-ee81e9c11c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topics_3, conv_probs_3 = conv_topic_model_3.fit_transform(conversations_data_2023, conversations_embeddings_gte_base_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa50199-b248-4323-bc86-80778d16c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topics_over_time_3 = conv_topic_model_3.topics_over_time(conversations_data_2023, timestamps_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637778c-c7d3-47d8-aaf4-467faf67ed8d",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28d016-c599-47fd-991d-44168b13be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_info_1 = conv_topic_model_1.get_topic_info()\n",
    "conv_topic_info_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63f6e9-6d15-474c-bb61-5889b350ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_info_2 = conv_topic_model_2.get_topic_info()\n",
    "conv_topic_info_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68c4bb-d3b7-4ee9-8a52-321cfea86227",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_info_3 = conv_topic_model_3.get_topic_info()\n",
    "conv_topic_info_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a0f31-a6a9-4421-92dc-fa37da7cf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_topic_model_1.save(\"conv_topic_model_1.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ced387-05b7-4312-9b57-3c80ee9c7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_topic_model_2.save(\"conv_topic_model_2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757864d7-b8a8-4d3a-9319-c30baab53df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_topic_model_3.save(\"conv_topic_model_3.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6cf32-60bc-47a6-94fe-09e66609c4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6952a03-42e6-4395-baca-a964411f4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"oulieres = {conv_topic_info_1.loc[0, 'Count'] / conv_topic_info_1['Count'].sum() * 100:.4}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a44f09-9441-48da-9b58-2853abd64efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"oulieres = {conv_topic_info_2.loc[0, 'Count'] / conv_topic_info_2['Count'].sum() * 100:.4}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884df55c-93c9-4405-bff2-adfa5a32766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"oulieres = {conv_topic_info_3.loc[0, 'Count'] / conv_topic_info_3['Count'].sum() * 100:.4}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359a0e2-8092-4596-88e1-fbd8cefad07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "  display(conv_topic_info_1.set_index('Topic')[['Count', 'Name', 'Representation']].iloc[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02a9ea-b898-4d7d-ae93-fd5e4ad47f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "  display(conv_topic_info_2.set_index('Topic')[['Count', 'Name', 'Representation']].iloc[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28955b7d-0e96-4a83-b734-d9214c3d2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "  display(conv_topic_info_3.set_index('Topic')[['Count', 'Name', 'Representation']].iloc[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e98e89-f80f-4a65-859a-e311e9175891",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_data_topics_1 = conv_topic_model_1.get_document_info(conversations_data_2023).merge(df_conversations_unique_2023, how='left', left_index=True, right_index=True)\n",
    "conversations_data_topics_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9899e2f-690e-4d8d-baf7-d6e7a7b751c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_data_topics_2 = conv_topic_model_2.get_document_info(conversations_data_2023).merge(df_conversations_unique_2023, how='left', left_index=True, right_index=True)\n",
    "conversations_data_topics_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef6a0f-e235-4907-a8b0-dad6da57e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_data_topics_3 = conv_topic_model_3.get_document_info(conversations_data_2023).merge(df_conversations_unique_2023, how='left', left_index=True, right_index=True)\n",
    "conversations_data_topics_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994fdb2-421e-44a8-a750-8f9beaf3c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(conv_topic_info_1, x='Name', y='Count',\n",
    "             title=\"Number of conversation related to a given topic\",\n",
    "            height=800,\n",
    "            # text_auto=True\n",
    "            )\n",
    "# fig.update_xaxes(range=[0, 100])\n",
    "fig.update_layout(xaxis_title='Topic 1',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c67712-89cf-42f0-b86d-a55a988527ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(conv_topic_info_2, x='Name', y='Count',\n",
    "             title=\"Number of conversation related to a given topic\",\n",
    "            height=800,\n",
    "            # text_auto=True\n",
    "            )\n",
    "# fig.update_xaxes(range=[0, 100])\n",
    "fig.update_layout(xaxis_title='Topic 2',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150fc858-1b94-4c01-878d-9d05cad345e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(conv_topic_info_3, x='Name', y='Count',\n",
    "             title=\"Number of conversation related to a given topic\",\n",
    "            height=1000,\n",
    "            # text_auto=True\n",
    "            )\n",
    "# fig.update_xaxes(range=[0, 100])\n",
    "fig.update_layout(xaxis_title='Topic Name',\n",
    "                  yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0113a1-3aa8-4618-8b01-c7d6528c1b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f16cfb37-dc40-4755-925e-9b2766d5102f",
   "metadata": {},
   "source": [
    "## Topic results over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d861c-1653-4a04-8b8f-7dd4d45f46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_over_time(conversations_data_topics, conv_topic_info):\n",
    "    months = np.sort(conversations_data_topics['conversation_month'].unique())\n",
    "    topics = conv_topic_info['Topic'].values\n",
    "    \n",
    "    topics_over_time = [pd.DataFrame(index=topics)]\n",
    "    for month in months:\n",
    "        col = conversations_data_topics.loc[conversations_data_topics['conversation_month']==month, 'Topic'].value_counts().to_frame()\n",
    "        col = col.rename(columns={'Topic': month})\n",
    "        topics_over_time.append(col)\n",
    "        \n",
    "    topics_over_time_df = pd.concat(topics_over_time, axis='columns').fillna(0).astype(int).transpose().reset_index().rename(columns={'index': 'Month'})\n",
    "    topics_over_time_melt_df = topics_over_time_df.melt(id_vars='Month', var_name=\"Topic\", value_name='Frequency')\n",
    "    topics_over_time_melt_df = topics_over_time_melt_df.merge(conv_topic_info[['Topic', 'Name', 'Representation']], how='left', on='Topic')\n",
    "    \n",
    "    return topics_over_time_melt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d4287-fdc8-4bb8-876c-95d35a710fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topics_over_time_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8098e7b-fd19-4ba9-8e09-25db87f0747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topics_over_time = topics_over_time(conversations_data_topics_3, conv_topic_info_3)\n",
    "conv_topics_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd4eb1-5f33-4c74-8a67-155044888e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "fig = px.line(conv_topics_over_time[conv_topics_over_time['Topic']<top_n], \n",
    "              x='Month', y='Frequency', color='Name',\n",
    "              markers=True,\n",
    "              height=600)\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.update_yaxes(showgrid=True)\n",
    "fig.update_layout(legend_traceorder=\"normal\") \n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': f\"<b>Topics over Time for All Customers</b>\",\n",
    "        'y': .95,\n",
    "        'x': 0.40,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(\n",
    "            size=22,\n",
    "            color=\"Black\")\n",
    "    },\n",
    "    template=\"simple_white\",\n",
    "    width=1250,\n",
    "    height=600,\n",
    "    hoverlabel=dict(\n",
    "        # bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=\"<b>Global Topic Representation</b>\",\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358a363-8848-43ed-b4df-bfacdfeaf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topics_over_time_solana = topics_over_time(conversations_data_topics_3_solana, conv_topic_info_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b13a2-def5-452f-8a11-3670038c8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 4\n",
    "freq_topics = conv_topics_over_time_solana.groupby('Topic')['Frequency'].sum().sort_values(ascending=False)[:top_n]\n",
    "freq_topics_over_time = conv_topics_over_time_solana[conv_topics_over_time_solana['Topic'].isin(freq_topics.index)]\n",
    "\n",
    "fig = px.line(freq_topics_over_time, x='Month', y='Frequency', color='Name',\n",
    "              markers=True,\n",
    "              )\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.update_yaxes(showgrid=True)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': f\"<b>Topics over Time for Solana</b>\",\n",
    "        'y': .95,\n",
    "        'x': 0.40,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(\n",
    "            size=22,\n",
    "            color=\"Black\")\n",
    "    },\n",
    "    template=\"simple_white\",\n",
    "    width=1250,\n",
    "    height=600,\n",
    "    hoverlabel=dict(\n",
    "        # bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=\"<b>Global Topic Representation</b>\",\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca79b0-fd33-40e7-a248-12404a385e25",
   "metadata": {},
   "source": [
    "## Representative conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca521e-2183-4efa-bf32-e35a35bda484",
   "metadata": {},
   "source": [
    "##### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768f3e6-8667-47b1-867e-2a6025b004db",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nb_1 = 0\n",
    "\n",
    "print(conv_topic_info_1.loc[topic_nb_1 + 1, 'Representation'])\n",
    "print(conv_topic_info_1.loc[topic_nb_1 + 1, 'Count'])\n",
    "print(\"#\"*50)\n",
    "\n",
    "for item in conv_topic_info_1.loc[topic_nb_1 + 1, 'Representative_Docs']:\n",
    "    print(item)\n",
    "    print(\"#\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c85237-49e5-4cad-b483-01e9c3ad7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=12)\n",
    "selected_conv_id = rng.choice(conversations_data_topics_1.loc[conversations_data_topics_1['Topic']==topic_nb_1, 'conversation_id'], 10, replace=False)\n",
    "\n",
    "for conv_id in selected_conv_id:\n",
    "    print('-'*10 + str(conv_id) + '-'*10)\n",
    "    for idx, item in df_conv_selected.loc[df_conv_selected['conversation_id']==conv_id, :].iterrows():\n",
    "    # for idx, item in df_conv_filtered.loc[df_conv_filtered['conversation_id']==conv_id, :].iterrows():\n",
    "        print(f\"| {item['author_type']} | {item['body']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360a55b-c0b1-44bc-863c-40f232cd6a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "636f41ec-145b-4097-a4b1-3f84fd1bf105",
   "metadata": {},
   "source": [
    "##### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd2540-ff29-4b9e-8f2c-e142f603c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nb_2 = 0\n",
    "\n",
    "print(conv_topic_info_2.loc[topic_nb_2 + 1, 'Representation'])\n",
    "print(conv_topic_info_2.loc[topic_nb_2 + 1, 'Count'])\n",
    "print(\"#\"*50)\n",
    "\n",
    "for item in conv_topic_info_2.loc[topic_nb_2 + 1, 'Representative_Docs']:\n",
    "    print(item)\n",
    "    print(\"#\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ac020-9d82-4975-a7ab-efbe55f8f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=12)\n",
    "selected_conv_id = rng.choice(conversations_data_topics_2.loc[conversations_data_topics_2['Topic']==topic_nb_2, 'conversation_id'], 10, replace=False)\n",
    "\n",
    "for conv_id in selected_conv_id:\n",
    "    print('-'*10 + str(conv_id) + '-'*10)\n",
    "    for idx, item in df_conv_selected.loc[df_conv_selected['conversation_id']==conv_id, :].iterrows():\n",
    "    # for idx, item in df_conv_filtered.loc[df_conv_filtered['conversation_id']==conv_id, :].iterrows():\n",
    "        print(f\"| {item['author_type']} | {item['body']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc89f4b-cff8-455c-9f4b-5bca8e06207a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b529f040-f8dc-4d28-9c8f-abbd3a543e51",
   "metadata": {},
   "source": [
    "##### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752c29e-6d14-423f-a98c-227b4851f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nb_3 = 0\n",
    "\n",
    "print(conv_topic_info_3.loc[topic_nb_3 + 1, 'Representation'])\n",
    "print(conv_topic_info_3.loc[topic_nb_3 + 1, 'Count'])\n",
    "print(\"#\"*50)\n",
    "\n",
    "for item in conv_topic_info_3.loc[topic_nb_3 + 1, 'Representative_Docs']:\n",
    "    print(item)\n",
    "    print(\"#\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e5be7-2226-4d77-a072-df5fc5ec38a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=12)\n",
    "selected_conv_id = rng.choice(conversations_data_topics_3.loc[conversations_data_topics_3['Topic']==topic_nb_3, 'conversation_id'], 10, replace=False)\n",
    "\n",
    "for conv_id in selected_conv_id:\n",
    "    print('-'*10 + str(conv_id) + '-'*10)\n",
    "    for idx, item in df_conv_selected.loc[df_conv_selected['conversation_id']==conv_id, :].iterrows():\n",
    "    # for idx, item in df_conv_filtered.loc[df_conv_filtered['conversation_id']==conv_id, :].iterrows():\n",
    "        print(f\"| {item['author_type']} | {item['body']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de6a5d-e97b-4ea7-a2b1-bd8f3655fded",
   "metadata": {},
   "source": [
    "## Custom labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c4168-7660-4269-b960-4d10bfc4b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the topics by one of the other topic representations, like KeyBERTInspired\n",
    "\n",
    "keybert_topic_labels = {topic: \" | \".join(list(zip(*values))[0][:3]) for topic, values in conv_topic_model_3.topic_aspects_[\"KeyBERT\"].items()}\n",
    "keybert_topic_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557fdb5-5044-45e1-85ce-6ba7f17119f7",
   "metadata": {},
   "source": [
    "## Topic-Document Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882904b-26cb-42d9-8984-d4c215f6f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.probabilities_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380abe1-b669-4267-8284-3b233686bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.probabilities_[17002].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033706c-b288-4c6a-ac42-2c2610d083c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topic-document distribution for a single document\n",
    "conv_topic_model_3.visualize_distribution(conv_topic_model_3.probabilities_[17002], custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe7be5-4a83-41ca-9172-b70e9295adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_data_topics_3.loc[17002, 'Document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd902a-b2d0-41ba-b93f-8caaa71b7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.topics_[17002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529342ea-23c2-47f3-845d-f628c6036979",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.probabilities_[17002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b9d6e-2256-402a-b634-a47dba3b1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pred = conv_topic_model_3.transform(conversations_data_2023[17002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a546cc-d457-4220-a675-ff8c5a3bf2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38471ff7-6ec5-4c5b-b45b-752b854de5ef",
   "metadata": {},
   "source": [
    "## Visualize Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ebb79-c043-4b13-834a-d2a2e4bd4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca07e07-da45-437b-be0b-1450a2b98a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0c694-4fb9-437c-b6ec-ea8c82bfb207",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e089ec2-82a8-4787-8a98-83f4e2803470",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.visualize_barchart(top_n_topics = 16, n_words = 10, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c22513-745c-45a3-90ef-9a6e80daac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_3.visualize_topics_over_time(conv_topics_over_time_3, top_n_topics=10, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c903b-a05b-489e-84dd-192b6fc8ac0c",
   "metadata": {},
   "source": [
    "## Topic Reduction after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b3cc1-eba4-4a0e-96d9-d67eb55ab5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_1.reduce_topics(conversations_data_2023, nr_topics=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263948db-dcd0-4d50-aaf9-d1c1458d5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_1.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d08cb3-4638-4603-b940-6241affc069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_1.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b933ac-8ded-45ef-8fe7-65f7663a7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nb = 0\n",
    "topic_rep = pd.DataFrame(conv_topic_model_1.get_topic(topic_nb, full=True)).explode(['Main', 'KeyBERT'], ignore_index=True)\n",
    "rep_words = topic_rep.iloc[::2].reset_index(drop=True)\n",
    "rep_scors = topic_rep.iloc[1::2].add_suffix('_score').astype(float).reset_index(drop=True)\n",
    "topic_df = pd.concat([rep_words, rep_scors], axis=1)\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48cd5f-198b-458a-ba59-b9333ce96e0f",
   "metadata": {},
   "source": [
    "## Update Topic Representation after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f1a70-7f65-481e-9197-c52db04f2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_1.update_topics(conversations_data_2023, n_gram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3dd4b-8f27-4ac5-890c-4e7df6faf769",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_1.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf5e63-790b-42f7-9c42-24b1b73409e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_1.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a20826-838d-4b4e-8aad-f3cc657eb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nb = 0\n",
    "topic_rep = pd.DataFrame(conv_topic_model_1.get_topic(topic_nb, full=True)).explode(['Main', 'KeyBERT'], ignore_index=True)\n",
    "rep_words = topic_rep.iloc[::2].reset_index(drop=True)\n",
    "rep_scors = topic_rep.iloc[1::2].add_suffix('_score').astype(float).reset_index(drop=True)\n",
    "topic_df = pd.concat([rep_words, rep_scors], axis=1)\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d62b1c-e149-4513-ad1a-166c62855e77",
   "metadata": {},
   "source": [
    "## Outlier reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67863c-082d-4513-915f-ebbcc7af0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conv_topics_2), (np.array(conv_topics_2) == -1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d0a66-23e9-4275-819d-ef07a0390683",
   "metadata": {},
   "source": [
    "The default method for reducing outliers is by calculating the c-TF-IDF representations of outlier documents and assigning them to the best matching c-TF-IDF representations of non-outlier topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afb2d5-c1a9-41df-85b6-6291407bc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the `threshold` parameter to select the minimum distance or similarity when matching outlier documents with non-outlier topics. This allows the user to change the amount of outlier documents are assigned to non-outlier topics.\n",
    "\n",
    "# Reduce outliers using the `c-tf-idf` strategy\n",
    "new_conv_topics_2 = conv_topic_model_2.reduce_outliers(conversations_data_2023, conv_topics_2, strategy=\"c-tf-idf\", threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbb200-947a-47f0-9cce-77ed4506492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(new_conv_topics_2) == -1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea1b7d-1557-4121-b522-ca48a816b7cd",
   "metadata": {},
   "source": [
    "Use the topic distributions, as calculated with `.approximate_distribution` to find the most frequent topic in each outlier document. You can use the `distributions_params` variable to tweak the parameters of `.approximate_distribution`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b257c2a-e7da-433b-8dc4-8b2629a044a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce outliers using the `distributions` strategy\n",
    "new_conv_topics_2d = conv_topic_model_2.reduce_outliers(conversations_data_2023, conv_topics_2, strategy=\"distributions\", threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b74aa7-5525-4b9f-8fbd-c0d38391c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(new_conv_topics_2d) == -1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572975f-6330-4f6c-8807-1aa9e7b0eee7",
   "metadata": {},
   "source": [
    "Probabilities strategy uses the soft-clustering as performed by HDBSCAN to find the best matching topic for each outlier document. To use this, make sure to calculate the `probabilities` beforehand by instantiating BERTopic with `calculate_probabilities=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2be86-aef2-4157-9728-e650aa43cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce outliers using the `probabilities` strategy\n",
    "new_conv_topics_2p = conv_topic_model_2.reduce_outliers(conversations_data_2023, conv_topics_2, probabilities=conv_probs_2, strategy=\"probabilities\", threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cd140-380a-4078-9ed3-941b103047ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(new_conv_topics_2p) == -1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a79ad-3359-46cb-8e28-9568ca5fdc81",
   "metadata": {},
   "source": [
    "Using the embeddings of each outlier documents, find the best matching topic embedding using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f72b3a-81b6-4582-9f97-02d92dc2904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce outliers using the `embeddings` strategy\n",
    "new_conv_topics_2e = conv_topic_model_2.reduce_outliers(conversations_data_2023, conv_topics_2, strategy=\"embeddings\", embeddings=conversations_embeddings_gte_base_2023, threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c40dbc-502b-4cca-a939-7470858b7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(new_conv_topics_2e) == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc6336-cfee-4c01-bec0-72987cda113c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7293a1b-6d5a-4197-a7d2-3ee8a2f342ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce our embeddings to 2D as it will allows us to quickly iterate later on\n",
    "conversations_reduced_embeddings = UMAP(n_neighbors=20, n_components=2, min_dist=0.0, metric='cosine', \n",
    "                                        random_state=42).fit_transform(conversations_embeddings_gte_base_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f4fd1-91c0-47f4-8de5-e199f5082139",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_2.visualize_documents(conversations_data_2023, reduced_embeddings=conversations_reduced_embeddings, \n",
    "                                       hide_document_hover=True, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab986c54-c09e-41cd-b899-fdd8f6bf0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When outlier documents are generated, they are not used when modeling the topic representations. These documents are completely ignored when finding good descriptions of topics. Thus, after having reduced the number of outliers in your topic model, you might want to update the topic representations with the documents that now belong to actual topics.\n",
    "\n",
    "conv_topic_model_2.update_topics(conversations_data_2023, topics=new_conv_topics_2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e8bbf-1774-4c2d-8deb-a578403e3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_topic_model_2.visualize_documents(conversations_data_2023, reduced_embeddings=conversations_reduced_embeddings, \n",
    "                                       hide_document_hover=True, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1152b5-c910-44f0-857b-a2328c50305b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a4b60e5-b8ab-4bc4-bd31-0acb22165bd1",
   "metadata": {},
   "source": [
    "## Clusters similarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d9399-fe4c-4fdf-a5aa-8ca8d7bf8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set_a, set_b):\n",
    "    # intersection of two sets\n",
    "    intersection = len(set_a.intersection(set_b))\n",
    "    # union of two sets\n",
    "    union = len(set_a.union(set_b))\n",
    "    \n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5f800-1802-40fe-accc-c6614a03394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(data_topics_a, data_topics_b):\n",
    "    topics_a = np.sort(data_topics_a['Topic'].unique())\n",
    "    topics_b = np.sort(data_topics_b['Topic'].unique())\n",
    "    similarity_matrix = pd.DataFrame(0.0, index=topics_a, columns=topics_b)\n",
    "\n",
    "    for topic_a in topics_a:\n",
    "        set_a = set(data_topics_a.loc[data_topics_a['Topic']==topic_a, 'conversation_id'])\n",
    "        for topic_b in topics_b:\n",
    "            set_b = set(data_topics_b.loc[data_topics_b['Topic']==topic_b, 'conversation_id'])\n",
    "            similarity_matrix.loc[topic_a, topic_b] = jaccard_similarity(set_a, set_b)\n",
    "            \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94f0c6-45dc-4052-ad3b-fd3bf11ab791",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_1 = np.sort(conversations_data_topics_1['Topic'].unique())\n",
    "topics_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd07ee9-48b6-4a9c-a6fa-9872153a707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_2 = np.sort(conversations_data_topics_2['Topic'].unique())\n",
    "topics_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b47348-d83f-4f18-ae2f-99202dbcfbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_3 = np.sort(conversations_data_topics_3['Topic'].unique())\n",
    "topics_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f975fc-975c-4ab2-ad7a-90d552c79d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_1_2 = similarity_matrix(conversations_data_topics_1, conversations_data_topics_2)\n",
    "similarity_matrix_1_3 = similarity_matrix(conversations_data_topics_1, conversations_data_topics_3)\n",
    "similarity_matrix_2_3 = similarity_matrix(conversations_data_topics_2, conversations_data_topics_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbabbd-d159-473c-a0a9-30faf7fd6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(similarity_matrix_1_2, \n",
    "                labels=dict(x=\"Topic 2\", y=\"Topic 1\", color=\"Jaccard similarity\"),\n",
    "               text_auto='.2f',\n",
    "                color_continuous_scale='Hot_r',\n",
    "               height=800,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184aa460-12d6-40ba-87f6-c76ff5fe0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(similarity_matrix_1_3, \n",
    "                labels=dict(x=\"Topic 3\", y=\"Topic 1\", color=\"Jaccard similarity\"),\n",
    "               text_auto='.2f',\n",
    "                color_continuous_scale='Hot_r',\n",
    "               height=800,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a3a13-345e-423f-9f8b-955a5095ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(similarity_matrix_2_3, \n",
    "                labels=dict(x=\"Topic 3\", y=\"Topic 2\", color=\"Jaccard similarity\"),\n",
    "               text_auto='.2f',\n",
    "                color_continuous_scale='Hot_r',\n",
    "               height=800,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd1f0b8-73e2-40cc-ae52-e938a488630b",
   "metadata": {},
   "source": [
    "# Large Language Models (LLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd769731-d6c3-484e-9a1b-5e1ea5af3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from vertexai.preview import generative_models\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573d10e-0087-4212-a34a-89c46a4eeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation(conversations_data_topics, conv_id):\n",
    "    # conv_body = '\\n'.join([f\"- {item['body']}\" \n",
    "    #                        for _, item in df_conv_selected.loc[df_conv_selected['conversation_id']==conv_id, :].iterrows()])\n",
    "    return '- ' + conversations_data_topics.loc[conversations_data_topics['conversation_id']==conv_id, 'Document'].item().replace('\\n', '\\n- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f5e8b-48c5-48b0-b459-9363b8233877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def select_conversation_docs(conversations_data_topics, topic_nb, nb_of_convs=10, method='highest_score'):\n",
    "    rng = np.random.default_rng(seed=12)\n",
    "    \n",
    "    topic_conversations = conversations_data_topics.loc[conversations_data_topics['Topic']==topic_nb, :].sort_values('Probability', ascending=False)\n",
    "    topic_conversations_probabilities = normalize([topic_conversations['Probability'].values], norm=\"l1\").ravel()\n",
    "    selected_conv_id = []\n",
    "\n",
    "    if method == 'highest_score':\n",
    "        # Select conversations with the highest probability score\n",
    "        selected_conv_id = topic_conversations.iloc[:nb_of_convs]['conversation_id']\n",
    "    elif method == 'score_dist':\n",
    "        # Select conversations based on their probability distribution\n",
    "        selected_conv_id = rng.choice(topic_conversations['conversation_id'], nb_of_convs, replace=False, p=topic_conversations_probabilities)\n",
    "    elif method == 'uniform':\n",
    "        # Select conversations based on uniform distribution over all chats\n",
    "        selected_conv_id = rng.choice(topic_conversations, nb_of_convs, replace=False)\n",
    "    \n",
    "    conversation_docs_str = \"\"\n",
    "    for nb_of_conv, conv_id in enumerate(selected_conv_id, 1):\n",
    "        conv_body = format_conversation(conversations_data_topics, conv_id) \n",
    "        conversation_docs_str += f'Conversation {nb_of_conv}\\n{conv_body}\\n\\n'\n",
    "\n",
    "    return conversation_docs_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc04c4d-2c37-4826-8bc6-18d1aa1db0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_response(model_response):\n",
    "    model_response_series = model_response.iloc[:,-1].str.replace(r'\\n+', '\\n', regex=True).str.replace(r'(-\\s(?:\\*\\*)?.+:(?:\\*\\*)?)\\s+-(.+)', lambda m: m.group(1) + m.group(2), regex=True).str.split('\\n')\n",
    "    model_response_exploded = model_response_series.explode().to_frame()\n",
    "    model_response_final = model_response_exploded.iloc[:,-1].str.extract(r'-\\s(?:\\*\\*)?(.+):(?:\\*\\*)?\\s(.+)').rename(columns={0: 'Pain point', 1: 'Explanation'}).reset_index()\n",
    "    return model_response_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a217f7-c77c-4420-99d0-fad983f24044",
   "metadata": {},
   "source": [
    "# GCP PaLM model (text-bison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90862831-80ac-458e-ab9e-16ded11ccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=\"helix-ds-metal-dev\", location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e15651-cb74-4ca8-afd4-102fb9dbe914",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"candidate_count\": 1,\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "# model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison-32k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0937054-48f3-4aa9-83bc-abf1c4091992",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6299b-c77e-419a-8e1a-55385145bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_1 = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c56bf8-ce4d-44cd-afc8-e95d9f4fa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_1a = \"\"\" \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387e63a-95bb-4bee-bcbb-a061d5da6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.predict(\n",
    "    f\"\"\"What is the set of main pain points extracted from the below conversation:\n",
    "    {conversation_1}\n",
    "    \"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model:\\n{response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35e394-2d7d-43df-aa19-d182c7f83e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.predict(\n",
    "    f\"\"\"What is the set of main pain points extracted from the below conversation:\n",
    "    {conversation_1a}\n",
    "    \"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model:\\n{response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a345b3-c241-4834-b24e-0e78dd03d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ...},\\n...'\n",
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"KEYWORDS\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"KEYWORDS\": ...},\\n...'\n",
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"INSIGHTS\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"INSIGHTS\": ...},\\n...'\n",
    "CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"ACTIONABLE INSIGHTS\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"ACTIONABLE INSIGHTS\": ...},\\n ...'\n",
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"ACTIONABLE INSIGHTS\": ..., \"KEYWORDS\": [...]},\\n{\"PAIN POINT\": ..., \"ACTIONABLE INSIGHTS\": ..., \"KEYWORDS\": [...]},\\n ...'\n",
    "\n",
    "response = model.predict(\n",
    "    f\"\"\"\n",
    "You are a helpful, respectful and honest Equinix assistant who extracts information from customer conversations.\n",
    "\n",
    "I have the following conversation:\n",
    "{conversation_1}\n",
    "\n",
    "Can you extract short but descriptive customer pain points and actionable insights from the above conversation? Provide the answer in the following format: {CONTENT_FORMAT}\n",
    "\"\"\",\n",
    "    \n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model:\\n{response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e0fcf-1d20-4ade-b782-6b38bd896a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0784d5e8-3d76-4406-bf64-c50401b4fc73",
   "metadata": {},
   "source": [
    "## Extract pain points from found topics and documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aaa2e8-b541-469f-8cfe-5ee17ec240eb",
   "metadata": {},
   "source": [
    "### All topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a867ff6-6c29-4700-af69-9ef38c32f0b9",
   "metadata": {},
   "source": [
    "#### Prompt build using multiple representative conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b74fa0-45a9-4d81-a0ce-d449e52c3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_nb = 20\n",
    "model_response_multi_list = []\n",
    "\n",
    "for topic_nb in tqdm(conv_topic_info_3['Topic']):    \n",
    "    # conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'Representation']\n",
    "    conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'KeyBERT']\n",
    "    current_convs_nb = 18 if topic_nb in [47] else convs_nb\n",
    "    conv_docs = select_conversation_docs(conversations_data_topics_3, topic_nb, current_convs_nb)\n",
    "    \n",
    "#     prompt = f\"\"\"\n",
    "# You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "# I have the following conversations:\n",
    "\n",
    "# {conv_docs.strip()}\n",
    "\n",
    "# The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "# Based on the above information, can you extract a short but highly descriptive pain points? Provide a maximum of 2 main pain points. Make sure it is in the following format:\n",
    "# - <pain point> Explanation of this <pain point>\n",
    "# \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "I have the following conversations:\n",
    "\n",
    "{conv_docs.strip()}\n",
    "\n",
    "The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "Based on the above information, can you extract a short but highly descriptive main pain point? Make sure it is in the following format:\n",
    "- <pain point>: Explanation of this <pain point>\n",
    "\"\"\"\n",
    "    \n",
    "    # print(f\"\"\"Topic {topic_nb}: prompt length {len(prompt)}, {conv_kyewords}\"\"\")\n",
    "    # print(prompt)\n",
    "    \n",
    "    prompt_response = model.predict(\n",
    "        prompt,\n",
    "        **parameters\n",
    "    )\n",
    "    model_response_multi_list.append(prompt_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ab0e2-5b97-419b-ae28-4db602d6bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, item in enumerate(model_response_multi_list, -1):\n",
    "#     print(f\"Topic {idx}:\")\n",
    "#     print(item)\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ed98d-000b-42b1-beb1-4558bd7bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response_multi_df = pd.DataFrame(model_response_multi_list, index=range(-1, len(model_response_multi_list) -1)).rename(columns={0: 'PaLM 2'})\n",
    "model_response_multi_df.index.name = 'Topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039d81f-6dde-4315-a7f3-b2eb6289bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(model_response_multi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313a577-4e77-47e9-9b10-71bb9a1c8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm_model_response_multi_df = format_model_response(model_response_multi_df)\n",
    "palm_model_response_multi_df['Pain point'] = palm_model_response_multi_df['Pain point'].str.replace(r'\\*\\*', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05270d84-6171-43a5-a63a-fe45f739992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(palm_model_response_multi_df.iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708d7ed-4f31-463a-a2c5-b2ed18012541",
   "metadata": {},
   "source": [
    "#### Prompt to solve pain points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3768ad-4f1e-4081-9faa-20db7b3bdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_nb = 20\n",
    "model_response_multi_solve_list = []\n",
    "\n",
    "for topic_nb in tqdm(conv_topic_info_3['Topic']):    \n",
    "    # conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'Representation']\n",
    "    conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'KeyBERT']\n",
    "    current_convs_nb = 18 if topic_nb in [47] else convs_nb\n",
    "    conv_docs = select_conversation_docs(conversations_data_topics_3, topic_nb, current_convs_nb)\n",
    "    \n",
    "    solve_prompt = f\"\"\"\n",
    "You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "I have the following conversations:\n",
    "\n",
    "{conv_docs.strip()}\n",
    "\n",
    "The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "Based on the above information, can you describe methods used to solve pain points? Provide a maximum of 2 main pain points. Make sure it is in the following format:\n",
    "- pain point \n",
    "  Method used to solve this pain point\n",
    "\"\"\"\n",
    "    \n",
    "    # print(f\"\"\"Topic {topic_nb}: prompt length {len(solve_prompt)}, {conv_kyewords}\"\"\")\n",
    "    # print(solve_prompt)\n",
    "    \n",
    "    prompt_response = model.predict(\n",
    "        solve_prompt,\n",
    "        **parameters\n",
    "    )\n",
    "    model_response_multi_solve_list.append(prompt_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890dbe8-87fc-4940-90db-bbbcdb80562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(model_response_multi_solve_list, -1):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    print(item)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef709d3c-8282-4b9e-8a91-509829dea451",
   "metadata": {},
   "source": [
    "#### Prompt to generate actionable insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a6530-96dc-4fa2-93f9-3c7c904e767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_nb = 20\n",
    "model_response_multi_insights_list = []\n",
    "\n",
    "for topic_nb in tqdm(conv_topic_info_3['Topic']):    \n",
    "    # conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'Representation']\n",
    "    conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'KeyBERT']\n",
    "    current_convs_nb = 18 if topic_nb in [47] else convs_nb\n",
    "    conv_docs = select_conversation_docs(conversations_data_topics_3, topic_nb, current_convs_nb)\n",
    "    \n",
    "    solve_prompt = f\"\"\"\n",
    "You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "I have the following conversations:\n",
    "\n",
    "{conv_docs.strip()}\n",
    "\n",
    "The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "Based on the above information, can you generate actionable insights that can help make decisions?\n",
    "\"\"\"\n",
    "    \n",
    "    # print(f\"\"\"Topic {topic_nb}: prompt length {len(solve_prompt)}, {conv_kyewords}\"\"\")\n",
    "    # print(solve_prompt)\n",
    "    \n",
    "    prompt_response = model.predict(\n",
    "        solve_prompt,\n",
    "        **parameters\n",
    "    )\n",
    "    model_response_multi_insights_list.append(prompt_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a850b-469c-44e2-8216-ca012d7fdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(model_response_multi_insights_list, -1):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    print(item)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278ef34-c1d3-4892-9c39-20eaded0adb6",
   "metadata": {},
   "source": [
    "# GCP Geminni Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1223ae2-ffb8-48b9-b32c-2e3d7c5d42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "vertexai.init(project=\"helix-ds-metal-dev\", location=\"us-central1\")\n",
    "\n",
    "# Load the model\n",
    "gemini_model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
    "\n",
    "# Generation config\n",
    "gemini_parameters = {\n",
    "    \"max_output_tokens\": 4096,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1,\n",
    "    # \"top_k\": 32\n",
    "}\n",
    "\n",
    "# Safety config\n",
    "safety_config = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95266eda-b32e-47b4-8090-af200057809a",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb604e1-a7d8-4b9e-bbe9-47d787540e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_1 = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee81b19-58c4-4df9-b831-6c51331ba1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_1a = \"\"\" \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da0bbf-2b76-49cb-8734-326e79f0703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_response = gemini_model.generate_content(\n",
    "    f\"\"\"What is the set of main pain points extracted from the below conversation:\n",
    "    {conversation_1}\n",
    "    \"\"\",\n",
    "    generation_config=gemini_parameters,\n",
    "    safety_settings=safety_config,\n",
    ")\n",
    "print(f\"Response from Model:\\n{gemini_response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbc655-f538-480d-8b8e-94f753a5a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ...},\\n...'\n",
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"KEYWORDS\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"KEYWORDS\": ...},\\n...'\n",
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"INSIGHTS\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"INSIGHTS\": ...},\\n...'\n",
    "CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"ACTIONABLE INSIGHTS\": ...},\\n{\"PAIN POINT\": ..., \"EXPLANATION\": ..., \"ACTIONABLE INSIGHTS\": ...},\\n ...'\n",
    "# CONTENT_FORMAT = '{\"PAIN POINT\": ..., \"ACTIONABLE INSIGHTS\": ..., \"KEYWORDS\": [...]},\\n{\"PAIN POINT\": ..., \"ACTIONABLE INSIGHTS\": ..., \"KEYWORDS\": [...]},\\n ...'\n",
    "\n",
    "gemini_response = gemini_model.generate_content(\n",
    "    f\"\"\"\n",
    "You are a helpful, respectful and honest assistant who extracts information from customer conversations.\n",
    "\n",
    "Extract short but descriptive customer pain points and actionable insights from the following conversation:\n",
    "{conversation_1}\n",
    "\n",
    "Provide the answer in the following format:\n",
    "{CONTENT_FORMAT}\n",
    "\"\"\",\n",
    "\n",
    "    generation_config=gemini_parameters,\n",
    "    safety_settings=safety_config,\n",
    ")\n",
    "print(f\"Response from Model:\\n{gemini_response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cba98c-6334-4a32-99cb-1e0e91fb8a00",
   "metadata": {},
   "source": [
    "## Extract pain points from found topics and documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c30118d-8a88-4b46-8e05-602edddadaaf",
   "metadata": {},
   "source": [
    "### All topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4e313-3a82-429b-bcdd-b64d32c0b5a3",
   "metadata": {},
   "source": [
    "#### Prompt build using multiple representative conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f200e-3b86-4439-8abf-0fb1b79c616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "vertexai.init(project=\"helix-ds-metal-dev\", location=\"us-central1\")\n",
    "\n",
    "# Load the model\n",
    "gemini_model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "# Generation config\n",
    "gemini_parameters = {\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1,\n",
    "    # \"top_k\": 32\n",
    "}\n",
    "\n",
    "# Safety config\n",
    "safety_config = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b58e15-3bfa-4e8e-8de6-6eb54b3838df",
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_nb = 20\n",
    "gemini_model_response_multi_list = []\n",
    "\n",
    "for topic_nb in tqdm(conv_topic_info_3['Topic']):    \n",
    "    # conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'Representation']\n",
    "    conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'KeyBERT']\n",
    "    current_convs_nb = 18 if topic_nb in [47] else convs_nb\n",
    "    conv_docs = select_conversation_docs(conversations_data_topics_3, topic_nb, current_convs_nb)\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "I have the following conversations:\n",
    "\n",
    "{conv_docs.strip()}\n",
    "\n",
    "The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "Based on the above information, can you extract a short but highly descriptive main pain point? Make sure it is in the following format:\n",
    "- <pain point>: Explanation of this <pain point>\n",
    "\"\"\"\n",
    "    \n",
    "#     prompt = f\"\"\"\n",
    "# You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "# I have the following conversations:\n",
    "\n",
    "# {conv_docs.strip()}\n",
    "\n",
    "# The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "# Based on the above information, can you extract a short but highly descriptive pain points? Provide a maximum of 2 main pain points. Make sure it is in the following format:\n",
    "# - <pain point> Explanation of this <pain point>\n",
    "# \"\"\"\n",
    "    \n",
    "    # print(f\"\"\"Topic {topic_nb}: prompt length {len(prompt)}, {conv_kyewords}\"\"\")\n",
    "    # print(prompt)\n",
    "    \n",
    "    gemini_prompt_response = gemini_model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=gemini_parameters,\n",
    "        safety_settings=safety_config,\n",
    "    )\n",
    "    \n",
    "    gemini_model_response_multi_list.append(gemini_prompt_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d7398-4bf4-46e4-963c-27b040466cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(gemini_model_response_multi_list, -1):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    print(item)\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d9250-7e7b-47d6-8303-e31149dc339a",
   "metadata": {},
   "source": [
    "##### 20 conversation per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db92b7b-98c9-4e61-9c8d-de629f200ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model_response_multi_20_df = pd.DataFrame(gemini_model_response_multi_list, index=range(-1, len(gemini_model_response_multi_list) -1)).rename(columns={0: 'Gemini Pro'})\n",
    "gemini_model_response_multi_20_df.index.name = 'Topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666908f5-c5dd-40e3-99c1-3f3f99b8d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(gemini_model_response_multi_20_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7ae6a-b609-4430-a559-a5e4e7bdb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model_response_multi_20_formatted = format_model_response(gemini_model_response_multi_20_df)\n",
    "gemini_model_response_multi_20_formatted['Pain point'] = gemini_model_response_multi_20_formatted['Pain point'].str.replace(r'\\*\\*', '')\n",
    "gemini_model_response_multi_20_formatted#.to_csv('gemini_model_response_multi_hs_20_2pp.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83152b-4243-4722-815d-277f6029d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(gemini_model_response_multi_20_formatted.iloc[:11])\n",
    "    # display(pd.read_csv('gemini_model_response_multi_hs_20.csv', sep='\\t')[:39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575bb941-c6a2-4172-b1aa-0b87cd934394",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 11\n",
    "freq_topics = conv_topics_over_time_top_customers.groupby('Topic')['Frequency'].sum().sort_values(ascending=False)[:top_n]\n",
    "\n",
    "gemini_model_response_multi_20_top_customers = gemini_model_response_multi_20_formatted[gemini_model_response_multi_20_formatted['Topic'].isin(freq_topics.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67511a-d9bf-4a77-943a-0fdd7e614e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(gemini_model_response_multi_20_top_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba00b7e-3310-4068-97f0-33e25810d4fb",
   "metadata": {},
   "source": [
    "##### 30 conversation per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ec7c7-e8dc-486d-a74d-3261bd6066ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini_model_response_multi_30_df = pd.DataFrame(gemini_model_response_multi_list, index=range(-1, len(gemini_model_response_multi_list) -1)).rename(columns={0: 'Gemini Pro'})\n",
    "# gemini_model_response_multi_30_df.index.name = 'Topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec916022-abda-483f-ae7d-01d6b04a35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_colwidth', None):\n",
    "#     display(gemini_model_response_multi_30_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9445965-9ac6-4b7f-81e8-6dd110642740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6f2df-5356-448f-84ab-7e9faf077899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_model_response(gemini_model_response_multi_30_df)#to_csv('gemini_model_response_multi_hs_30_2pp.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839ee62-dd76-4c84-8ac5-43c36a9fe698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46839f0-f709-4001-a076-41d55ff639a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_colwidth', None):\n",
    "#     display(format_model_response(gemini_model_response_multi_30_df))\n",
    "    # display(pd.read_csv('gemini_model_response_multi_hs_30.csv', sep='\\t')[:39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf26f2e-8f17-44b3-98cc-0f14e88626c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_colwidth', None):\n",
    "#     display(pd.read_csv('gemini_model_response_multi_hs_30_2pp.csv', sep='\\t')[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225e929-b9ed-4674-9f58-2ceb35af249e",
   "metadata": {},
   "source": [
    "#### Prompt to solve pain points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e449ef1-a2cd-4c25-bba1-980d0a8570a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "vertexai.init(project=\"helix-ds-metal-dev\", location=\"us-central1\")\n",
    "\n",
    "# Load the model\n",
    "gemini_model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "# Generation config\n",
    "gemini_parameters = {\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1,\n",
    "    # \"top_k\": 32\n",
    "}\n",
    "\n",
    "# Safety config\n",
    "safety_config = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce8a55-8a83-457d-9597-375b103e560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_nb = 20\n",
    "gemini_model_response_multi_solve_list = []\n",
    "\n",
    "for topic_nb in tqdm(conv_topic_info_3['Topic']):    \n",
    "    # conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'Representation']\n",
    "    conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'KeyBERT']\n",
    "    current_convs_nb = 15 if topic_nb in [47] else convs_nb\n",
    "    conv_docs = select_conversation_docs(conversations_data_topics_3, topic_nb, current_convs_nb)\n",
    "\n",
    "\n",
    "    solve_prompt = f\"\"\"\n",
    "You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "I have the following conversations:\n",
    "\n",
    "{conv_docs.strip()}\n",
    "\n",
    "The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "Based on the above information, can you describe methods used to solve pain points? Provide a maximum of 2 main pain points. Make sure it is in the following format:\n",
    "- pain point \n",
    "  Method used to solve this pain point\n",
    "\"\"\"\n",
    "    \n",
    "    # print(f\"\"\"Topic {topic_nb}: prompt length {len(solve_prompt)}, {conv_kyewords}\"\"\")\n",
    "    # print(prompt)\n",
    "    \n",
    "    gemini_prompt_response = gemini_model.generate_content(\n",
    "        solve_prompt,\n",
    "        generation_config=gemini_parameters,\n",
    "        safety_settings=safety_config,\n",
    "    )\n",
    "    \n",
    "    gemini_model_response_multi_solve_list.append(gemini_prompt_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97f088-4026-424e-8022-79d69d693145",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(gemini_model_response_multi_solve_list, -1):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    print(item)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7788c9-5044-40d1-80f2-f75ec19fc774",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model_response_multi_20_solve_df = pd.DataFrame(gemini_model_response_multi_solve_list, index=range(-1, len(gemini_model_response_multi_solve_list) -1)).rename(columns={0: 'Gemini Pro'})\n",
    "gemini_model_response_multi_20_solve_df.index.name = 'Topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25240905-f1e9-40fb-9574-8d67ce7d94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(gemini_model_response_multi_20_solve_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20452f6c-778a-4c7e-98ce-fe059e41abf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca4567c-54dc-4afa-9f7d-7311d4c58079",
   "metadata": {},
   "source": [
    "#### Prompt to generate actionable insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1938d2-714b-41ab-adca-93519981b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "vertexai.init(project=\"helix-ds-metal-dev\", location=\"us-central1\")\n",
    "\n",
    "# Load the model\n",
    "gemini_model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "# Generation config\n",
    "gemini_parameters = {\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1,\n",
    "    # \"top_k\": 32\n",
    "}\n",
    "\n",
    "# Safety config\n",
    "safety_config = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa4068-ff86-494d-bd97-1741dc5b6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "convs_nb = 20\n",
    "gemini_model_response_multi_insights_list = []\n",
    "\n",
    "for topic_nb in freq_topics.index:\n",
    "    # conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'Representation']\n",
    "    conv_kyewords = conv_topic_info_3.loc[topic_nb + 1, 'KeyBERT']\n",
    "    current_convs_nb = 15 if topic_nb in [47] else convs_nb\n",
    "    conv_docs = select_conversation_docs(conversations_data_topics_3, topic_nb, current_convs_nb)\n",
    "\n",
    "\n",
    "    solve_prompt = f\"\"\"\n",
    "You are a helpful, respectful and honest assistant for extracting information from conversations.\n",
    "\n",
    "I have the following conversations:\n",
    "\n",
    "{conv_docs.strip()}\n",
    "\n",
    "The conversations are described by the following keywords: {', '.join(conv_kyewords)}\n",
    "\n",
    "Based on the above information, can you generate actionable insights that can help make decisions?\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"\"\"Topic {topic_nb}: prompt length {len(solve_prompt)}, {conv_kyewords}\"\"\")\n",
    "    # print(prompt)\n",
    "    \n",
    "    gemini_prompt_response = gemini_model.generate_content(\n",
    "        solve_prompt,\n",
    "        generation_config=gemini_parameters,\n",
    "        safety_settings=safety_config,\n",
    "    )\n",
    "    \n",
    "    gemini_model_response_multi_insights_list.append(gemini_prompt_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103a9c1-a651-4845-ad64-7728b92963b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in zip(freq_topics.index, gemini_model_response_multi_insights_list):\n",
    "    print(f\"Topic {idx}:\\n\")\n",
    "    print(item)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
